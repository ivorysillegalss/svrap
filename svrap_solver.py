import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import math
import os # æ–°å¢: ç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„

# ==========================================
# 1. é…ç½®ä¸ç¯å¢ƒ (Configuration & Environment)
# ==========================================

class SVRAPConfig:
    RAW_DATA = """
37,52
49,49
52,64
20,26
40,30
21,47
17,63
31,62
52,33
51,21
42,41
31,32
5,25
12,42
36,16
52,41
27,23
17,33
13,13
57,58
62,42
42,57
16,57
8,52
7,38
27,68
30,48
43,67
58,48
58,27
37,69
38,46
46,10
61,33
62,63
63,69
32,22
45,35
59,15
5,6
10,17
21,10
5,64
30,15
39,10
32,39
25,32
25,55
48,28
56,37
30,40
"""
    # å¼ºåŒ–å­¦ä¹ å‚æ•°
    SEED = 42
    EMBED_DIM = 128
    N_HEADS = 4
    LR = 1e-4
    EPOCHS = 1000
    
    # SVRAP ç›®æ ‡å‡½æ•°å‚æ•° (åŸºäºæ‚¨çš„å…¬å¼å’Œä¸šåŠ¡å®šä¹‰)
    GAMMA = 2.0      # åˆ†é…æˆæœ¬ç³»æ•° (C_ij = D_ij * GAMMA)
    LAMBDA_ISOL = 0.5  # **éš”ç¦»æˆæœ¬æƒé‡å› å­ (Î»_isol)**

    # **æ–°å¢é…ç½®ï¼šæ¨¡å‹ä¿å­˜è·¯å¾„**
    MODEL_PATH = "svrap_best_model.pth"

class SVRAPEnvironment:
    def __init__(self, raw_data):
        self.coords, self.norm_coords = self._parse_and_normalize(raw_data)
        self.n_nodes = len(self.coords)
        
        # æ ¹æ®èŠ‚ç‚¹åˆ°ä¸­å¿ƒç‚¹çš„è·ç¦»æ¨¡æ‹Ÿ D_i (å›ºæœ‰éš”ç¦»æˆæœ¬)
        center = self.coords.mean(dim=0)
        dist_to_center = torch.norm(self.coords - center, dim=1)
        max_dist = dist_to_center.max()
        if max_dist > 0:
            norm_dist = dist_to_center / max_dist
        else:
            norm_dist = torch.zeros_like(dist_to_center)

        self.node_isolation_cost = 5.0 + 15.0 * norm_dist # (N,)
        torch.manual_seed(SVRAPConfig.SEED)
        
        self.dist_matrix, self.cost_matrix = self._compute_matrices()
        
    def _parse_and_normalize(self, raw_data):
        coords = []
        for line in raw_data.strip().split('\n'):
            parts = line.strip().split(',')
            coords.append([float(parts[0]), float(parts[1])])
        coords_tensor = torch.tensor(coords, dtype=torch.float32)
        
        min_vals, _ = coords_tensor.min(dim=0)
        max_vals, _ = coords_tensor.max(dim=0)
        range_vals = max_vals - min_vals
        norm_coords = (coords_tensor - min_vals) / torch.where(range_vals > 0, range_vals, torch.ones_like(range_vals))
        return coords_tensor, norm_coords

    def _compute_matrices(self):
        x = self.norm_coords
        diff = x.unsqueeze(1) - x.unsqueeze(0)
        dist = torch.norm(diff, dim=-1)
        cost = dist * SVRAPConfig.GAMMA
        return dist.unsqueeze(0), cost.unsqueeze(0)

    def evaluate_solution(self, actions):
        """
        è®¡ç®—ç›®æ ‡å‡½æ•°æ€»æˆæœ¬ (æœ€å°åŒ–):
        æ€»æˆæœ¬ = è·¯ç”±æˆæœ¬ + åˆ†é…æˆæœ¬ + éš”ç¦»æˆæœ¬
        Actions: 0=Assign, 1=Route, 2=Loss (å¯¹åº” v_i=1)
        """
        actions = actions.cpu().numpy()
        assign_indices = [i for i, a in enumerate(actions) if a == 0]
        route_indices = [i for i, a in enumerate(actions) if a == 1]
        loss_indices = [i for i, a in enumerate(actions) if a == 2] # å¯¹åº” v_i=1
        backbone_indices = route_indices
        
        d_mat = self.dist_matrix[0]
        c_mat = self.cost_matrix[0]
        
        # 1. è·¯ç”±æˆæœ¬ (Route Cost)
        if len(backbone_indices) < 2:
            route_cost = 1000.0 
        else:
            route_cost = 0
            for k in range(len(backbone_indices)):
                u, v = backbone_indices[k], backbone_indices[(k + 1) % len(backbone_indices)]
                route_cost += d_mat[u, v].item()
            
        # 2. åˆ†é…æˆæœ¬ (Assignment Cost)
        assign_cost = 0
        if len(backbone_indices) > 0:
            for nb_idx in assign_indices:
                min_c_to_backbone = min([c_mat[nb_idx, b].item() for b in backbone_indices])
                assign_cost += min_c_to_backbone
        
        # 3. éš”ç¦»æˆæœ¬ (Isolation Cost)
        isolation_cost_sum = sum(self.node_isolation_cost[i].item() for i in loss_indices)
        isolation_cost = SVRAPConfig.LAMBDA_ISOL * isolation_cost_sum

        total_cost = route_cost + assign_cost + isolation_cost
        
        if len(assign_indices) > 0 and len(backbone_indices) == 0:
             total_cost += 1000.0
            
        return total_cost

# ==========================================
# 2. æ¨¡å‹æ¶æ„ (Model Architecture) - ä¿æŒä¸å˜
# ==========================================

class GatedEdgeFusion(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.gate = nn.Sequential(nn.Linear(2, dim), nn.ReLU(), nn.Linear(dim, 1), nn.Sigmoid())
        self.proj = nn.Linear(2, 1) 
    def forward(self, d, c):
        feat = torch.stack([d, c], dim=-1)
        z = self.gate(feat)
        bias = self.proj(feat * z)
        return bias.squeeze(-1)

class SVRAPNetwork(nn.Module):
    def __init__(self, n_nodes):
        super().__init__()
        dim = SVRAPConfig.EMBED_DIM
        self.node_emb = nn.Linear(2, dim)
        self.edge_fusion = GatedEdgeFusion(32)
        self.attn = nn.MultiheadAttention(dim, SVRAPConfig.N_HEADS, batch_first=True)
        self.ff = nn.Sequential(nn.Linear(dim, dim*2), nn.ReLU(), nn.Linear(dim*2, dim))
        self.norm1 = nn.LayerNorm(dim)
        self.norm2 = nn.LayerNorm(dim)
        self.head = nn.Linear(dim, 3) 

    def forward(self, x, d, c):
        h = self.node_emb(x)
        attn_bias = self.edge_fusion(d, c)
        h_key_bias = h + attn_bias.mean(dim=-1).unsqueeze(-1) 
        h2 = self.norm1(h)
        attn_out, _ = self.attn(h2, h_key_bias, h_key_bias)
        h = h + attn_out
        h2 = self.norm2(h)
        h = h + self.ff(h2)
        logits = self.head(h)
        return logits

# ==========================================
# 3. è®­ç»ƒä¸è¿è¡Œæµç¨‹ (Training & Workflow)
# ==========================================

def run_pipeline(train_model=True):
    # 1. åˆå§‹åŒ–
    torch.manual_seed(SVRAPConfig.SEED)
    env = SVRAPEnvironment(SVRAPConfig.RAW_DATA)
    model = SVRAPNetwork(env.n_nodes)
    
    x = env.norm_coords.unsqueeze(0)
    d = env.dist_matrix
    c = env.cost_matrix
    
    # --- åŠ è½½/è®­ç»ƒé€»è¾‘ ---
    best_cost = float('inf')
    best_actions_tensor = None
    
    if os.path.exists(SVRAPConfig.MODEL_PATH) and not train_model:
        # **åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹**
        print(f"âœ… å‘ç°å·²ä¿å­˜æ¨¡å‹: {SVRAPConfig.MODEL_PATH}ã€‚è·³è¿‡è®­ç»ƒï¼Œç›´æ¥åŠ è½½...")
        checkpoint = torch.load(SVRAPConfig.MODEL_PATH)
        model.load_state_dict(checkpoint['model_state_dict'])
        best_cost = checkpoint['best_cost']
        best_actions_tensor = checkpoint['best_actions_tensor']
        
    elif train_model:
        # **å¼€å§‹è®­ç»ƒ**
        optimizer = optim.Adam(model.parameters(), lr=SVRAPConfig.LR)
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: èŠ‚ç‚¹æ•° {env.n_nodes}, ç›®æ ‡: æœ€å°åŒ–æ€»æˆæœ¬")
        
        baseline = 0
        model.train()
        for epoch in range(SVRAPConfig.EPOCHS):
            optimizer.zero_grad()
            logits = model(x, d, c)
            probs = F.softmax(logits, dim=-1)
            dist = torch.distributions.Categorical(probs)
            actions = dist.sample()
            
            cost = env.evaluate_solution(actions[0])
            
            if cost < best_cost:
                best_cost = cost
                # ä¿å­˜æœ€ä¼˜çŠ¶æ€
                best_actions_tensor = actions.clone().detach() 
                
                # **æ–°å¢: å®æ—¶ä¿å­˜æœ€ä½³æ¨¡å‹**
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'best_cost': best_cost,
                    'best_actions_tensor': best_actions_tensor,
                }, SVRAPConfig.MODEL_PATH)
            
            reward = -cost
            if epoch == 0: baseline = reward
            else: baseline = 0.95 * baseline + 0.05 * reward
            
            advantage = reward - baseline
            log_probs = dist.log_prob(actions)
            loss = -(log_probs * advantage).mean()
            
            loss.backward()
            optimizer.step()
            
            if epoch % 100 == 0:
                route_count = (actions == 1).sum().item()
                loss_count = (actions == 2).sum().item()
                print(f"Epoch {epoch:04d} | Cost: {cost:.4f} | Best: {best_cost:.4f} | R/L Count: {route_count}/{loss_count}")
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆã€‚æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜åˆ° {SVRAPConfig.MODEL_PATH}")

    # 4. æœ€ç»ˆç»“æœå±•ç¤º
    print("\n" + "="*70)
    print("æœ€ç»ˆç»“æœå±•ç¤º (Final Results)")
    print("="*70)
    print(f"æœ€ä¼˜æ€»æˆæœ¬ (Best Cost): {best_cost:.4f}")

    # ç¡®ä¿ä½¿ç”¨ä¿å­˜çš„æœ€ä¼˜åŠ¨ä½œè¿›è¡Œè¯„ä¼°å±•ç¤º
    if best_actions_tensor is not None:
        final_actions = best_actions_tensor.squeeze().cpu().tolist()
        final_route = [i for i, a in enumerate(final_actions) if a == 1]
        final_loss = [i for i, a in enumerate(final_actions) if a == 2]
        
        print(f"æœ€ä¼˜è§£ - ROUTE èŠ‚ç‚¹: {final_route}")
        print(f"æœ€ä¼˜è§£ - LOSS èŠ‚ç‚¹:   {final_loss}")
    
    model.eval()
    with torch.no_grad():
        final_logits = model(x, d, c)
        final_probs = F.softmax(final_logits, dim=-1)
    
    final_probs_np = final_probs[0].cpu().numpy()
    
    print("\n" + "="*70)
    print("èŠ‚ç‚¹æœ€ç»ˆæ¦‚ç‡ç­–ç•¥ä¸æœ€ä¼˜è§£çŠ¶æ€å¯¹æ¯”")
    print("="*70)
    print("ID | X,Y åæ ‡ | P_Assign | P_Route | P_Loss | æœ€ä¼˜è§£çŠ¶æ€")
    print("-" * 70)
    
    status_map = {0: 'ASSIGN', 1: 'ROUTE', 2: 'LOSS'}
    for i in range(env.n_nodes):
        p_assign, p_route, p_loss = final_probs_np[i]
        coord = env.coords[i].numpy()
        
        if best_actions_tensor is not None:
            action_status = status_map[final_actions[i]]
        else:
            action_status = "N/A"
        
        print(f"{i:2d} | {coord[0]:.0f},{coord[1]:.0f} | {p_assign:.4f} | {p_route:.4f} | {p_loss:.4f} | {action_status:10s}")
        
    print("-" * 70)


if __name__ == "__main__":
    # ç¬¬ä¸€æ¬¡è¿è¡Œï¼šè¿›è¡Œè®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹
    # run_pipeline(train_model=True) 
    
    # ç¬¬äºŒæ¬¡è¿è¡Œï¼šç›´æ¥åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹ï¼Œè·³è¿‡è®­ç»ƒ
    # run_pipeline(train_model=False) 
    
    # é»˜è®¤è¡Œä¸ºï¼šå¦‚æœæ–‡ä»¶å­˜åœ¨åˆ™åŠ è½½ï¼Œå¦åˆ™è®­ç»ƒ
    if os.path.exists(SVRAPConfig.MODEL_PATH):
        run_pipeline(train_model=False)
    else:
        run_pipeline(train_model=True)