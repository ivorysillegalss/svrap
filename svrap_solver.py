import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import math
import os 

# ==========================================
# 1. é…ç½®ä¸ç¯å¢ƒ (Configuration & Environment)
# ==========================================

class SVRAPConfig:
    # å®¢æˆ·åæ ‡æ•°æ® (51ä¸ªå®¢æˆ·ï¼Œå¯¹åº” n=51)
    RAW_DATA = """
37,52
49,49
52,64
20,26
40,30
21,47
17,63
31,62
52,33
51,21
42,41
31,32
5,25
12,42
36,16
52,41
27,23
17,33
13,13
57,58
62,42
42,57
16,57
8,52
7,38
27,68
30,48
43,67
58,48
58,27
37,69
38,46
46,10
61,33
62,63
63,69
32,22
45,35
59,15
5,6
10,17
21,10
5,64
30,15
39,10
32,39
25,32
25,55
48,28
56,37
30,40
"""
    # å¼ºåŒ–å­¦ä¹ å‚æ•°
    SEED = 42
    EMBED_DIM = 128
    N_HEADS = 4
    LR = 1e-4
    EPOCHS = 1000
    
    # **æ ¸å¿ƒ SVRAP é—®é¢˜å‚æ•° (åŸºäºåŸæ–‡)**
    PARAM_A = 7.0  # åå‘å› å­ a (å½±å“ c_ij, d_ij å’Œ lambda_isol)
    
    # æƒé‡å› å­ (åŸºäºåŸæ–‡ - å…è®¸å­¤ç«‹é¡¶ç‚¹)
    LAMBDA_TOUR = 1.0  # lambda_tour = 1
    LAMBDA_ALLOC = 1.0 # lambda_alloc = 1
    # LAMBDA_ISOL å°†åœ¨ç¯å¢ƒåˆå§‹åŒ–æ—¶åŠ¨æ€è®¡ç®—: 0.5 + 0.0004 * a^2 * n

    # è´ªå¿ƒ/æ¨¡å‹é…ç½®
    TOP_K_ROUTE_RATIO = 0.2  # é€‰å– P_Route æœ€é«˜çš„ 20% èŠ‚ç‚¹ä½œä¸ºåˆå§‹éª¨å¹²
    MODEL_PATH = "svrap_best_model.pth"

class SVRAPEnvironment:
    def __init__(self, raw_data):
        self.coords, self.norm_coords = self._parse_and_normalize(raw_data)
        self.n_nodes = len(self.coords) # åŒ…å«æ‰€æœ‰å®¢æˆ·èŠ‚ç‚¹
        self.param_a = SVRAPConfig.PARAM_A
        torch.manual_seed(SVRAPConfig.SEED)
        
        # 1. è®¡ç®—æ‰€æœ‰çŸ©é˜µ (è·ç¦», è·¯ç”±æˆæœ¬, åˆ†é…æˆæœ¬)
        # è¿™é‡Œçš„è·ç¦» l_ij å¯¹åº”ä»£ç ä¸­çš„ dist
        self.dist_matrix, self.route_cost_matrix, self.alloc_cost_matrix = self._compute_matrices()
        
        # 2. è®¡ç®—éš”ç¦»æˆæœ¬æƒé‡ (lambda_isol)
        # n æ˜¯å®¢æˆ·é¡¶ç‚¹æ•°é‡ï¼Œè¿™é‡Œ self.n_nodes å°±æ˜¯å®¢æˆ·æ•° N=51
        # å…¬å¼: lambda_isol = 0.5 + 0.0004 * a^2 * n
        self.lambda_isol = 0.5 + 0.0004 * (self.param_a ** 2) * self.n_nodes
        
        # 3. è®¡ç®—éš”ç¦»æˆæœ¬ D_i (å®¢æˆ· i åˆ†é…ç»™ä»»ä½•å…¶ä»–é¡¶ç‚¹ j çš„æœ€ä½æˆæœ¬)
        # D_i = min(d_ij | j != i)
        
        # alloc_cost_matrix[0] æ˜¯ d_ij = (10 - a) * l_ij
        temp_alloc_cost = self.alloc_cost_matrix[0].clone() 
        
        # æ’é™¤å¯¹è§’çº¿ d_iiï¼Œå³è‡ªå·±åˆ†é…ç»™è‡ªå·±ä¸è®¡ç®—åœ¨å†…
        diag_val = torch.inf
        temp_alloc_cost.fill_diagonal_(diag_val) 
        
        # D_i æ˜¯æ¯ä¸€è¡Œï¼ˆå®¢æˆ· iï¼‰åˆ°æ‰€æœ‰å…¶ä»–å®¢æˆ·çš„æœ€å°åˆ†é…æˆæœ¬
        self.node_isolation_cost, _ = temp_alloc_cost.min(dim=1) 
        
        print(f"SVRAP ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ: a={self.param_a}, å®¢æˆ·èŠ‚ç‚¹ n={self.n_nodes}")
        print(f"åŠ¨æ€è®¡ç®—çš„ Lambda_isol: {self.lambda_isol:.4f}")
        
    def _parse_and_normalize(self, raw_data):
        coords = []
        for line in raw_data.strip().split('\n'):
            parts = line.strip().split(',')
            coords.append([float(parts[0]), float(parts[1])])
        coords_tensor = torch.tensor(coords, dtype=torch.float32)
        
        min_vals, _ = coords_tensor.min(dim=0)
        max_vals, _ = coords_tensor.max(dim=0)
        range_vals = max_vals - min_vals
        norm_coords = (coords_tensor - min_vals) / torch.where(range_vals > 0, range_vals, torch.ones_like(range_vals))
        return coords_tensor, norm_coords

    def _compute_matrices(self):
        x = self.norm_coords
        diff = x.unsqueeze(1) - x.unsqueeze(0)
        dist = torch.norm(diff, dim=-1) # l_ij (æ¬§æ°è·ç¦»)
        
        # è·¯ç”±æˆæœ¬ c_ij = a * l_ij
        route_cost = dist * self.param_a 
        
        # åˆ†é…æˆæœ¬ d_ij = (10 - a) * l_ij
        alloc_cost = dist * (10.0 - self.param_a)
        
        return dist.unsqueeze(0), route_cost.unsqueeze(0), alloc_cost.unsqueeze(0)

    def evaluate_solution(self, actions):
        """
        è®¡ç®—ç›®æ ‡å‡½æ•°æ€»æˆæœ¬ (æœ€å°åŒ–):
        Total Cost = lambda_tour * Tour + lambda_alloc * Allocation + lambda_isol * Isolation
        Actions: 0=Assign, 1=Route, 2=Loss
        """
        # ä¿®æ­£ï¼šç¡®ä¿ actions æ˜¯ä¸€ç»´çš„ (N,)
        actions = actions.squeeze().cpu().numpy()
        if actions.ndim == 0:
             actions = np.array([actions.item()])
        
        assign_indices = [i for i, a in enumerate(actions) if a == 0]
        route_indices = [i for i, a in enumerate(actions) if a == 1]
        loss_indices = [i for i, a in enumerate(actions) if a == 2] 
        backbone_indices = route_indices
        
        route_mat = self.route_cost_matrix[0] # c_ij
        alloc_mat = self.alloc_cost_matrix[0] # d_ij
        
        # --- 1. è·¯ç”±æˆæœ¬ (Tour Cost) ---
        # lambda_tour * sum(c_ij * x_ij)
        route_cost_sum = 0
        if len(backbone_indices) < 2:
            route_cost_sum = 1000.0 # æƒ©ç½šæ— æ•ˆè·¯å¾„
        else:
            for k in range(len(backbone_indices)):
                u, v = backbone_indices[k], backbone_indices[(k + 1) % len(backbone_indices)]
                # route_mat[u, v] å·²ç»æ˜¯ c_ij = a * l_ij
                route_cost_sum += route_mat[u, v].item()
        
        tour_cost = SVRAPConfig.LAMBDA_TOUR * route_cost_sum
            
        # --- 2. åˆ†é…æˆæœ¬ (Allocation Cost) ---
        # lambda_alloc * sum(d_ij * y_ij)
        assign_cost_sum = 0
        if len(backbone_indices) > 0:
            for nb_idx in assign_indices:
                # å¯»æ‰¾æœ€å°åˆ†é…æˆæœ¬ d_ijã€‚alloc_mat[nb_idx, b] å·²ç»æ˜¯ d_ij = (10-a)*l_ij
                min_d_to_backbone = min([alloc_mat[nb_idx, b].item() for b in backbone_indices])
                assign_cost_sum += min_d_to_backbone

        allocation_cost = SVRAPConfig.LAMBDA_ALLOC * assign_cost_sum
        
        # --- 3. éš”ç¦»æˆæœ¬ (Isolation Cost) ---
        # lambda_isol * sum(D_i * v_i)
        isolation_cost_sum = 0
        for i in loss_indices:
             # D_i æ˜¯é¢„å…ˆè®¡ç®—çš„æœ€ä½åˆ†é…æˆæœ¬ min(d_ij)
            isolation_cost_sum += self.node_isolation_cost[i].item()
            
        # lambda_isol æ˜¯åŠ¨æ€è®¡ç®—çš„ self.lambda_isol
        isolation_cost = self.lambda_isol * isolation_cost_sum

        # æœ€ç»ˆæ€»æˆæœ¬
        total_cost = tour_cost + allocation_cost + isolation_cost
        
        # é¢å¤–æƒ©ç½šï¼šå¦‚æœå­˜åœ¨ ASSIGN èŠ‚ç‚¹ä½†æ²¡æœ‰ ROUTE éª¨å¹²
        if len(assign_indices) > 0 and len(backbone_indices) == 0:
             total_cost += 1000.0
            
        return total_cost

# ==========================================
# 2. æ¨¡å‹æ¶æ„ (Model Architecture) - ä¿æŒä¸å˜
# ==========================================

class GatedEdgeFusion(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.gate = nn.Sequential(nn.Linear(2, dim), nn.ReLU(), nn.Linear(dim, 1), nn.Sigmoid())
        self.proj = nn.Linear(2, 1) 
    def forward(self, d, c):
        feat = torch.stack([d, c], dim=-1)
        z = self.gate(feat)
        bias = self.proj(feat * z)
        return bias.squeeze(-1)

class SVRAPNetwork(nn.Module):
    def __init__(self, n_nodes):
        super().__init__()
        dim = SVRAPConfig.EMBED_DIM
        self.node_emb = nn.Linear(2, dim)
        self.edge_fusion = GatedEdgeFusion(32)
        self.attn = nn.MultiheadAttention(dim, SVRAPConfig.N_HEADS, batch_first=True)
        self.ff = nn.Sequential(nn.Linear(dim, dim*2), nn.ReLU(), nn.Linear(dim*2, dim))
        self.norm1 = nn.LayerNorm(dim)
        self.norm2 = nn.LayerNorm(dim)
        self.head = nn.Linear(dim, 3) 

    def forward(self, x, d, c):
        # è·¯ç”±æˆæœ¬çŸ©é˜µ d å’Œ åˆ†é…æˆæœ¬çŸ©é˜µ c ç”¨äºæŒ‡å¯¼æ³¨æ„åŠ›
        h = self.node_emb(x)
        attn_bias = self.edge_fusion(d, c)
        h_key_bias = h + attn_bias.mean(dim=-1).unsqueeze(-1) 
        h2 = self.norm1(h)
        attn_out, _ = self.attn(h2, h_key_bias, h_key_bias)
        h = h + attn_out
        h2 = self.norm2(h)
        h = h + self.ff(h2)
        logits = self.head(h)
        return logits

# ==========================================
# 3. è®­ç»ƒä¸è¿è¡Œæµç¨‹ (Training & Workflow)
# ==========================================

def run_pipeline(train_model=True):
    # 1. åˆå§‹åŒ–
    torch.manual_seed(SVRAPConfig.SEED)
    env = SVRAPEnvironment(SVRAPConfig.RAW_DATA)
    model = SVRAPNetwork(env.n_nodes)
    
    x = env.norm_coords.unsqueeze(0)
    # å°†è·¯ç”±æˆæœ¬çŸ©é˜µå’Œåˆ†é…æˆæœ¬çŸ©é˜µä½œä¸ºç‰¹å¾è¾“å…¥
    route_cost_tensor = env.route_cost_matrix 
    alloc_cost_tensor = env.alloc_cost_matrix
    
    # --- åŠ è½½/è®­ç»ƒé€»è¾‘ ---
    best_cost = float('inf')
    best_actions_tensor = None
    
    if os.path.exists(SVRAPConfig.MODEL_PATH) and not train_model:
        # **åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹**
        print(f"âœ… å‘ç°å·²ä¿å­˜æ¨¡å‹: {SVRAPConfig.MODEL_PATH}ã€‚è·³è¿‡è®­ç»ƒï¼Œç›´æ¥åŠ è½½...")
        checkpoint = torch.load(SVRAPConfig.MODEL_PATH)
        model.load_state_dict(checkpoint['model_state_dict'])
        best_cost = checkpoint['best_cost']
        best_actions_tensor = checkpoint['best_actions_tensor']
        
    elif train_model:
        # **å¼€å§‹è®­ç»ƒ**
        optimizer = optim.Adam(model.parameters(), lr=SVRAPConfig.LR)
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: èŠ‚ç‚¹æ•° {env.n_nodes}, ç›®æ ‡: æœ€å°åŒ–æ€»æˆæœ¬")
        
        baseline = 0
        model.train()
        for epoch in range(SVRAPConfig.EPOCHS):
            optimizer.zero_grad()
            # ä½¿ç”¨è·¯ç”±å’Œåˆ†é…æˆæœ¬ä½œä¸ºæ³¨æ„åŠ›è¾“å…¥ç‰¹å¾
            logits = model(x, route_cost_tensor, alloc_cost_tensor)
            probs = F.softmax(logits, dim=-1)
            dist = torch.distributions.Categorical(probs)
            actions = dist.sample()
            
            cost = env.evaluate_solution(actions) # actions å·²ç»æ˜¯ (B, N)
            
            if cost < best_cost:
                best_cost = cost
                best_actions_tensor = actions.clone().detach() 
                
                # å®æ—¶ä¿å­˜æœ€ä½³æ¨¡å‹
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'best_cost': best_cost,
                    'best_actions_tensor': best_actions_tensor,
                }, SVRAPConfig.MODEL_PATH)
            
            reward = -cost
            if epoch == 0: baseline = reward
            else: baseline = 0.95 * baseline + 0.05 * reward
            
            advantage = reward - baseline
            log_probs = dist.log_prob(actions)
            loss = -(log_probs * advantage).mean()
            
            loss.backward()
            optimizer.step()
            
            if epoch % 100 == 0:
                actions_np = actions.squeeze().cpu().numpy()
                route_count = (actions_np == 1).sum().item()
                loss_count = (actions_np == 2).sum().item()
                print(f"Epoch {epoch:04d} | Cost: {cost:.4f} | Best: {best_cost:.4f} | R/L Count: {route_count}/{loss_count}")
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆã€‚æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜åˆ° {SVRAPConfig.MODEL_PATH}")

    # 4. æœ€ç»ˆç»“æœå±•ç¤ºå’Œè´ªå¿ƒé€‰æ‹©
    print("\n" + "="*70)
    print("æœ€ç»ˆç»“æœå±•ç¤º (Final Results)")
    print("="*70)
    print(f"æœ€ä¼˜æ€»æˆæœ¬ (Best Cost): {best_cost:.4f}")

    final_actions = best_actions_tensor.squeeze().cpu().tolist() if best_actions_tensor is not None else []
    
    if best_actions_tensor is not None:
        final_route = [i for i, a in enumerate(final_actions) if a == 1]
        final_loss = [i for i, a in enumerate(final_actions) if a == 2]
        
        print(f"æœ€ä¼˜è§£ - ROUTE èŠ‚ç‚¹: {final_route}")
        print(f"æœ€ä¼˜è§£ - LOSS èŠ‚ç‚¹:   {final_loss}")
    
    model.eval()
    with torch.no_grad():
        final_logits = model(x, route_cost_tensor, alloc_cost_tensor)
        final_probs = F.softmax(final_logits, dim=-1)
    
    final_probs_np = final_probs[0].cpu().numpy()
    
    # --- åŸºäºè´ªå¿ƒç­–ç•¥çš„åˆå§‹éª¨å¹²æ„å»º (Greedy Backbone Selection) ---
    
    p_route = final_probs_np[:, 1] # è·å– On-route æ¦‚ç‡ (åŠ¨ä½œ 1)
    sorted_indices = np.argsort(p_route)[::-1] # èŠ‚ç‚¹æŒ‰ P_Route é™åºæ’åº
    
    n_nodes = env.n_nodes
    k = max(2, int(n_nodes * SVRAPConfig.TOP_K_ROUTE_RATIO)) # ç¡®å®šè´ªå¿ƒé€‰æ‹©çš„æ•°é‡ K
    greedy_backbone_indices = sorted_indices[:k].tolist() # é€‰å–å‰ K ä¸ªèŠ‚ç‚¹ä½œä¸ºåˆå§‹éª¨å¹²
    
    # è¯„ä¼°è¿™ä¸ªè´ªå¿ƒè§£çš„å®Œæ•´æˆæœ¬ (ROUTE=1, ASSIGN=0)
    greedy_actions = np.zeros(n_nodes, dtype=int)
    greedy_actions[greedy_backbone_indices] = 1 # ROUTE
    greedy_cost = env.evaluate_solution(torch.tensor(greedy_actions).unsqueeze(0)) 

    # -----------------------------------------------------------------
    
    print("\n" + "="*70)
    print("èŠ‚ç‚¹æœ€ç»ˆæ¦‚ç‡ç­–ç•¥ä¸æœ€ä¼˜è§£çŠ¶æ€å¯¹æ¯”")
    print("="*70)
    print("ID | X,Y åæ ‡ | P_Assign | P_Route | P_Loss | æœ€ä¼˜è§£çŠ¶æ€ | è´ªå¿ƒéª¨å¹²?")
    print("-" * 80)
    
    status_map = {0: 'ASSIGN', 1: 'ROUTE', 2: 'LOSS'}
    for i in range(env.n_nodes):
        p_assign, p_route_val, p_loss = final_probs_np[i]
        coord = env.coords[i].numpy()
        
        action_status = status_map[final_actions[i]] if best_actions_tensor is not None else "N/A"
        is_greedy_backbone = "âœ…" if i in greedy_backbone_indices else " "
        
        print(f"{i:2d} | {coord[0]:.0f},{coord[1]:.0f} | {p_assign:.4f} | {p_route_val:.4f} | {p_loss:.4f} | {action_status:10s} | {is_greedy_backbone:^8s}")
        
    print("-" * 80)
    print(f"**è´ªå¿ƒé€‰æ‹©ç»“æœ (K={k}, é˜ˆå€¼: P_Route æœ€é«˜çš„ {SVRAPConfig.TOP_K_ROUTE_RATIO*100:.0f}%)**")
    print(f"è´ªå¿ƒåˆå§‹éª¨å¹²èŠ‚ç‚¹ (ROUTE): {greedy_backbone_indices}")
    print(f"è¯„ä¼°è´ªå¿ƒè§£æ€»æˆæœ¬: {greedy_cost:.4f}")
    print("="*70)


if __name__ == "__main__":
    # é»˜è®¤è¡Œä¸ºï¼šå¦‚æœæ–‡ä»¶å­˜åœ¨åˆ™åŠ è½½ï¼Œå¦åˆ™è®­ç»ƒ
    if os.path.exists(SVRAPConfig.MODEL_PATH):
        run_pipeline(train_model=False)
    else:
        run_pipeline(train_model=True)